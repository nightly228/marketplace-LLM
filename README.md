# marketplace-LLM
# Marketplace Reviews — LLM классификация отзывов

Гугл-колаб: https://colab.research.google.com/drive/1s50wqOA9s60Ts57XApdmNmDXLhrSSV5V

**Цель проекта:** классификация отзывов с маркетплейсов по категориям товаров (включая "нет товара").

## Структура репозитория
- `notebook/ллм.ipynb` — основной ноутбук с решением.
- `requirements.txt` — зависимости проекта.

## Данные
-## Данные
- Датасеты train.csv, test.csv, submission_example.csv нужно скачать самостоятельно с [официального источника](https://data.tinkoff.ru/s/QKAc6RXwKRck6Bs)
- После скачивания загрузить их в ноутбук для работы.

## Как запустить
1. Открыть `notebook/ллм.ipynb` в Google Colab.
2. Загрузить `train.csv`, `test.csv`, `submission_example.csv`.
3. Runtime → Change runtime type → GPU (рекомендуется).
4. Run → Run all.

## Подход
1. **Pseudo-labeling:** Sentence-BERT кодирует категории и отзывы; каждому отзыву присваивается ближайшая категория.
2. **TF-IDF + Logistic Regression:** обучение классификатора на псевдоразмеченных данных.
3. **Inference:** предсказания на тесте, сохранение в `submission.csv`.

##По шагам делала
1. загрузка файлов в ноутбук
2. генерация псевдоразметки(Используем SentenceTransformer (rubert-tiny) для векторизации текста. Создаем функцию get_category, которая ищет наиболее похожую категорию по косинусной близости. Применяем к тренировочным данным и сохраняем псевдоразмеченный train_pseudo.csv.)
3. Обучение модели(Преобразуем тексты в TF-IDF векторы. Обучаем LogisticRegression на псевдоразмеченных данных. Оцениваем качество на валидационной выборке с помощью метрики Weighted F1.)
4. Разметка тестового набора (Применяем обученную модель к тестовым отзывам. Создаем submission.csv для отправки.)
5. Установка зависимостей

   
## Результаты
- Weighted F1 (validation): 0.4568
- Среднее время инференса: ~1–2 сек на отзыв
- Распределение категорий после псевдоразметки:
- обувь: 708
нет товара: 406
посуда: 305
украшения и аксессуары: 204
бытовая техника: 92
одежда: 48
товары для детей: 27
текстиль: 25
электроника: 3
